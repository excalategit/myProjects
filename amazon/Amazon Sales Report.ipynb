{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690e39a3",
   "metadata": {},
   "source": [
    "The design here (based on best practice) is to load data to a staging table, transform and export dimension table data to their tables, create surrogate keys on those tables and import the surrogate keys back to the staging table. Afterwards transform and export fact table data together with all surrogate keys to the fact table. \n",
    "\n",
    "Note that this design sometimes require some transformation to be done on the data in staging before exporting to dimension tables. This is because at the step where surrogate keys are loaded back to staging, the action is based on a comparison between staging and dimension table data which will fail if one table is transformed and the other not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc368d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb509c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea5089",
   "metadata": {},
   "source": [
    "Creating the fact and dimension tables where the transformed data will be loaded to.\n",
    "\n",
    "Here the connection is defined with an additional specification for the schema since here the tables are not created on the default public schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bcc4c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = None\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "    \n",
    "try:\n",
    "    \n",
    "    with psycopg2.connect(\n",
    "        host = 'localhost',\n",
    "        dbname = 'Destination',\n",
    "        user = db_user,\n",
    "        password = db_password,\n",
    "        port = 5432,\n",
    "        options = '-c search_path=amazon') as connection:\n",
    "        # This is how to indicate the schema of interest\n",
    "    \n",
    "        with connection.cursor() as cursor:\n",
    "            \n",
    "            create_dim_product = '''\n",
    "            CREATE TABLE IF NOT EXISTS dim_product (\n",
    "            product_key SERIAL PRIMARY KEY,\n",
    "            product_id TEXT,\n",
    "            product_name TEXT,\n",
    "            category TEXT,\n",
    "            about_product TEXT,\n",
    "            img_link TEXT,\n",
    "            product_link TEXT,\n",
    "            rating TEXT,\n",
    "            rating_count TEXT\n",
    "            )'''\n",
    "            \n",
    "            cursor.execute(create_dim_product)          \n",
    "            \n",
    "            create_dim_user = '''\n",
    "            CREATE TABLE IF NOT EXISTS dim_user (\n",
    "            user_key SERIAL PRIMARY KEY,\n",
    "            user_id TEXT,\n",
    "            user_name TEXT\n",
    "            )'''\n",
    "            \n",
    "            cursor.execute(create_dim_user)\n",
    "            \n",
    "            create_dim_review = '''\n",
    "            CREATE TABLE IF NOT EXISTS dim_review (\n",
    "            review_key SERIAL PRIMARY KEY,\n",
    "            review_id TEXT,\n",
    "            review_title TEXT,\n",
    "            review_content TEXT\n",
    "            )'''\n",
    "            \n",
    "            cursor.execute(create_dim_review)\n",
    "            \n",
    "            create_fact_table = '''\n",
    "            CREATE TABLE IF NOT EXISTS fact_table (\n",
    "            \"discounted_price (PLN)\" FLOAT,\n",
    "            \"actual_price (PLN)\" FLOAT,\n",
    "            discount_percentage TEXT,\n",
    "            product_key INT REFERENCES dim_product (product_key),\n",
    "            user_key INT REFERENCES dim_user (user_key),\n",
    "            review_key INT REFERENCES dim_review (review_key)\n",
    "            )'''\n",
    "            \n",
    "            cursor.execute(create_fact_table)\n",
    "            \n",
    "except Exception as error:\n",
    "    print(error)\n",
    "    \n",
    "finally:\n",
    "    if connection is not None:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca4dfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that will perform the INSERT action when called by the ETL stages.\n",
    "\n",
    "def insert(x, y):\n",
    "    connection = None\n",
    "    db_user = os.getenv('DB_USER')\n",
    "    db_password = os.getenv('DB_PASSWORD')\n",
    "    \n",
    "    try:\n",
    "        with psycopg2.connect(\n",
    "            host = 'localhost',\n",
    "            dbname = 'Destination',\n",
    "            user = db_user,\n",
    "            password = db_password,\n",
    "            port = 5432) as connection:\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "\n",
    "                psycopg2.extras.execute_batch(cursor, x, y)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "\n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()\n",
    "            \n",
    "# Defining the function that extracts and transforms to staging\n",
    "\n",
    "def extract_transform():\n",
    "    connection = None\n",
    "    \n",
    "    try:\n",
    "        engine = create_engine('postgresql:///Source')\n",
    "        engine2 = create_engine('postgresql:///Destination')\n",
    "        \n",
    "        table_name = pd.read_sql('amazon_sales_report', engine) \n",
    "        table_name.to_sql('stg_amazon_sales_report', engine2, index=False, if_exists='replace')\n",
    "    \n",
    "        # Addition of surrogate key columns to staging\n",
    "        db_user = os.getenv('DB_USER')\n",
    "        db_password = os.getenv('DB_PASS')\n",
    "        \n",
    "        with psycopg2.connect(\n",
    "            host = 'localhost',\n",
    "            dbname = 'Destination',\n",
    "            user = db_user,\n",
    "            password = db_password,\n",
    "            port = 5432) as connection:\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "                \n",
    "                staging_update = '''ALTER TABLE stg_amazon_sales_report\n",
    "                ADD COLUMN product_key INT,\n",
    "                ADD COLUMN user_key INT,\n",
    "                ADD COLUMN review_key INT\n",
    "                '''\n",
    "                \n",
    "                cursor.execute(staging_update)\n",
    "                \n",
    "                return print('Extraction to staging completed')\n",
    "    \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        \n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()\n",
    "\n",
    "# Defining the function that loads the transformed data to the dimension tables\n",
    "\n",
    "def load_dim_product():\n",
    "\n",
    "    engine = create_engine('postgresql:///Destination')\n",
    "    \n",
    "    dp = pd.read_sql('stg_amazon_sales_report', engine)\n",
    "    product = dp[['product_id', 'product_name', 'category', 'about_product', 'img_link', 'product_link',\n",
    "                  'rating', 'rating_count']].copy()\n",
    "    product['rating_count'] = product['rating_count'].fillna(1)\n",
    "    product = product.drop_duplicates(subset=['product_id', 'product_name'], keep='first')\n",
    "    # It is best practice to deduplicate dim tables using business keys alone.\n",
    "    product = product.to_dict('records')\n",
    "\n",
    "    insert_query = '''INSERT into amazon.dim_product (\n",
    "    product_id,\n",
    "    product_name,\n",
    "    category,\n",
    "    about_product,\n",
    "    img_link,\n",
    "    product_link,\n",
    "    rating,\n",
    "    rating_count\n",
    "    ) \n",
    "    VALUES (\n",
    "    %(product_id)s,\n",
    "    %(product_name)s,\n",
    "    %(category)s,\n",
    "    %(about_product)s,\n",
    "    %(img_link)s,\n",
    "    %(product_link)s,\n",
    "    %(rating)s,\n",
    "    %(rating_count)s\n",
    "    )'''\n",
    "    \n",
    "    insert(insert_query, product)\n",
    "    return print('dim_product loaded successfully')\n",
    "\n",
    "def load_dim_user():\n",
    "    \n",
    "    engine = create_engine('postgresql:///Destination')\n",
    "    \n",
    "    du = pd.read_sql('stg_amazon_sales_report', engine)\n",
    "    user = du[['user_id', 'user_name']].copy()\n",
    "    user = user.drop_duplicates()\n",
    "    user = user.to_dict('records')\n",
    "\n",
    "    insert_query = '''INSERT into amazon.dim_user (\n",
    "    user_id,\n",
    "    user_name\n",
    "    ) \n",
    "    VALUES (\n",
    "    %(user_id)s,\n",
    "    %(user_name)s\n",
    "    )'''\n",
    "\n",
    "    insert(insert_query, user)\n",
    "    return print('dim_user loaded successfully')\n",
    "\n",
    "def load_dim_review():\n",
    "    \n",
    "    engine = create_engine('postgresql:///Destination')\n",
    "\n",
    "    drr = pd.read_sql('stg_amazon_sales_report', engine)\n",
    "    review = drr[['review_id', 'review_title', 'review_content']].copy()\n",
    "    review = review.drop_duplicates(subset=['review_id', 'review_title'], keep='first')\n",
    "    review = review.to_dict('records')\n",
    "\n",
    "    insert_query = '''INSERT into amazon.dim_review (\n",
    "    review_id,\n",
    "    review_title,\n",
    "    review_content\n",
    "    )\n",
    "    VALUES (\n",
    "    %(review_id)s,\n",
    "    %(review_title)s,\n",
    "    %(review_content)s\n",
    "    )'''\n",
    "\n",
    "    insert(insert_query, review)\n",
    "    return print('dim_review loaded successfully')\n",
    "\n",
    "# Defining the function that loads the surrogate keys to staging\n",
    "\n",
    "def load_surr_keys():\n",
    "    connection = None\n",
    "    db_user = os.getenv('DB_USER')\n",
    "    db_password = os.getenv('DB_PASSWORD')\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        with psycopg2.connect(\n",
    "            host = 'localhost',\n",
    "            dbname = 'Destination',\n",
    "            user = db_user,\n",
    "            password = db_password,\n",
    "            port = 5432) as connection:\n",
    "\n",
    "            with connection.cursor() as cursor:\n",
    "                \n",
    "                product_key = '''UPDATE stg_amazon_sales_report AS s SET product_key = p.product_key \n",
    "                FROM amazon.dim_product AS p WHERE s.product_id = p.product_id AND\n",
    "                s.product_name = p.product_name'''\n",
    "                cursor.execute(product_key)\n",
    "                \n",
    "                user_key = '''UPDATE stg_amazon_sales_report AS s SET user_key = u.user_key \n",
    "                FROM amazon.dim_user AS u WHERE s.user_id = u.user_id AND\n",
    "                s.user_name = u.user_name'''\n",
    "                cursor.execute(user_key)\n",
    "                \n",
    "                review_key = '''UPDATE stg_amazon_sales_report AS s SET review_key = rr.review_key \n",
    "                FROM amazon.dim_review AS rr WHERE s.review_id = rr.review_id AND\n",
    "                s.review_title = rr.review_title'''\n",
    "                cursor.execute(review_key)\n",
    "                \n",
    "                return print('staging updated with surr. keys successfully')\n",
    "    \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        \n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()\n",
    "            \n",
    "# Finally, defining the function that transforms and loads the fact table together with the surrogate keys\n",
    "            \n",
    "def transform_load_fact_table():\n",
    "    \n",
    "    engine = create_engine('postgresql:///Destination')\n",
    "    \n",
    "    dg = pd.read_sql('stg_amazon_sales_report', engine)\n",
    "    fact = dg[['discounted_price', 'actual_price', 'discount_percentage', \n",
    "               'product_key', 'user_key', 'review_key']].copy()\n",
    "\n",
    "    fact['discounted_price'] = fact['discounted_price'].str.replace('PLN ', '')\n",
    "    fact['discounted_price'] = fact['discounted_price'].str.replace(',', '').astype(float)\n",
    "    fact['actual_price'] = fact['actual_price'].str.replace('PLN ', '')\n",
    "    fact['actual_price'] = fact['actual_price'].str.replace(',', '').astype(float)\n",
    "    fact = fact.to_dict('records')\n",
    "\n",
    "    insert_query = '''INSERT into amazon.fact_table (\n",
    "    \"discounted_price (PLN)\",\n",
    "    \"actual_price (PLN)\",\n",
    "    discount_percentage,\n",
    "    product_key,\n",
    "    user_key,\n",
    "    review_key\n",
    "    ) \n",
    "    VALUES (\n",
    "    %(discounted_price)s,\n",
    "    %(actual_price)s,\n",
    "    %(discount_percentage)s,\n",
    "    %(product_key)s,\n",
    "    %(user_key)s,\n",
    "    %(review_key)s\n",
    "    )'''\n",
    "\n",
    "    insert(insert_query, fact)\n",
    "    return print('fact_table loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "935d4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction to staging completed\n"
     ]
    }
   ],
   "source": [
    "extract_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "608af032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_product loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dim_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efdfaa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_user loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dim_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3df444a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_review loaded successfully\n"
     ]
    }
   ],
   "source": [
    "load_dim_review()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1583ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging updated with surr. keys successfully\n"
     ]
    }
   ],
   "source": [
    "load_surr_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8956307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_table loaded successfully\n"
     ]
    }
   ],
   "source": [
    "transform_load_fact_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de652f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
